{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eec3204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple___Apple_scab\n",
      "Apple___Black_rot\n",
      "Apple___Cedar_apple_rust\n",
      "Apple___healthy\n",
      "Blueberry___healthy\n",
      "Cherry_(including_sour)___Powdery_mildew\n",
      "Cherry_(including_sour)___healthy\n",
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\n",
      "Corn_(maize)___Common_rust_\n",
      "Corn_(maize)___Northern_Leaf_Blight\n",
      "Corn_(maize)___healthy\n",
      "Grape___Black_rot\n",
      "Grape___Esca_(Black_Measles)\n",
      "Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\n",
      "Grape___healthy\n",
      "Orange___Haunglongbing_(Citrus_greening)\n",
      "Peach___Bacterial_spot\n",
      "Peach___healthy\n",
      "Pepper,_bell___Bacterial_spot\n",
      "Pepper,_bell___healthy\n",
      "Potato___Early_blight\n",
      "Potato___Late_blight\n",
      "Potato___healthy\n",
      "Raspberry___healthy\n",
      "Soybean___healthy\n",
      "Squash___Powdery_mildew\n",
      "Strawberry___Leaf_scorch\n",
      "Strawberry___healthy\n",
      "Tomato___Bacterial_spot\n",
      "Tomato___Early_blight\n",
      "Tomato___Late_blight\n",
      "Tomato___Leaf_Mold\n",
      "Tomato___Septoria_leaf_spot\n",
      "Tomato___Spider_mites Two-spotted_spider_mite\n",
      "Tomato___Target_Spot\n",
      "Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Tomato___Tomato_mosaic_virus\n",
      "Tomato___healthy\n"
     ]
    }
   ],
   "source": [
    "class_names = [\n",
    "    \"Apple___Apple_scab\",\n",
    "    \"Apple___Black_rot\",\n",
    "    \"Apple___Cedar_apple_rust\",\n",
    "    \"Apple___healthy\",\n",
    "    \"Blueberry___healthy\",\n",
    "    \"Cherry_(including_sour)___Powdery_mildew\",\n",
    "    \"Cherry_(including_sour)___healthy\",\n",
    "    \"Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot\",\n",
    "    \"Corn_(maize)___Common_rust_\",\n",
    "    \"Corn_(maize)___Northern_Leaf_Blight\",\n",
    "    \"Corn_(maize)___healthy\",\n",
    "    \"Grape___Black_rot\",\n",
    "    \"Grape___Esca_(Black_Measles)\",\n",
    "    \"Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\",\n",
    "    \"Grape___healthy\",\n",
    "    \"Orange___Haunglongbing_(Citrus_greening)\",\n",
    "    \"Peach___Bacterial_spot\",\n",
    "    \"Peach___healthy\",\n",
    "    \"Pepper,_bell___Bacterial_spot\",\n",
    "    \"Pepper,_bell___healthy\",\n",
    "    \"Potato___Early_blight\",\n",
    "    \"Potato___Late_blight\",\n",
    "    \"Potato___healthy\",\n",
    "    \"Raspberry___healthy\",\n",
    "    \"Soybean___healthy\",\n",
    "    \"Squash___Powdery_mildew\",\n",
    "    \"Strawberry___Leaf_scorch\",\n",
    "    \"Strawberry___healthy\",\n",
    "    \"Tomato___Bacterial_spot\",\n",
    "    \"Tomato___Early_blight\",\n",
    "    \"Tomato___Late_blight\",\n",
    "    \"Tomato___Leaf_Mold\",\n",
    "    \"Tomato___Septoria_leaf_spot\",\n",
    "    \"Tomato___Spider_mites Two-spotted_spider_mite\",\n",
    "    \"Tomato___Target_Spot\",\n",
    "    \"Tomato___Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "    \"Tomato___Tomato_mosaic_virus\",\n",
    "    \"Tomato___healthy\"\n",
    "]\n",
    "\n",
    "# Print the class names\n",
    "for name in class_names:\n",
    "    \n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6de5d20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer conv_layers.0.weight is frozen.\n",
      "Layer conv_layers.0.bias is frozen.\n",
      "Layer conv_layers.1.weight is frozen.\n",
      "Layer conv_layers.1.bias is frozen.\n",
      "Layer conv_layers.3.weight is frozen.\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
      "       BatchNorm2d-2         [-1, 64, 224, 224]             128\n",
      "              ReLU-3         [-1, 64, 224, 224]               0\n",
      "            Conv2d-4         [-1, 64, 224, 224]          36,928\n",
      "       BatchNorm2d-5         [-1, 64, 224, 224]             128\n",
      "              ReLU-6         [-1, 64, 224, 224]               0\n",
      "         MaxPool2d-7         [-1, 64, 112, 112]               0\n",
      "            Conv2d-8        [-1, 128, 112, 112]          73,856\n",
      "       BatchNorm2d-9        [-1, 128, 112, 112]             256\n",
      "             ReLU-10        [-1, 128, 112, 112]               0\n",
      "           Conv2d-11        [-1, 128, 112, 112]         147,584\n",
      "      BatchNorm2d-12        [-1, 128, 112, 112]             256\n",
      "             ReLU-13        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-14          [-1, 128, 56, 56]               0\n",
      "           Conv2d-15          [-1, 256, 56, 56]         295,168\n",
      "      BatchNorm2d-16          [-1, 256, 56, 56]             512\n",
      "             ReLU-17          [-1, 256, 56, 56]               0\n",
      "           Conv2d-18          [-1, 256, 56, 56]         590,080\n",
      "      BatchNorm2d-19          [-1, 256, 56, 56]             512\n",
      "             ReLU-20          [-1, 256, 56, 56]               0\n",
      "           Conv2d-21          [-1, 256, 56, 56]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 56, 56]             512\n",
      "             ReLU-23          [-1, 256, 56, 56]               0\n",
      "           Conv2d-24          [-1, 256, 56, 56]         590,080\n",
      "      BatchNorm2d-25          [-1, 256, 56, 56]             512\n",
      "             ReLU-26          [-1, 256, 56, 56]               0\n",
      "        MaxPool2d-27          [-1, 256, 28, 28]               0\n",
      "           Conv2d-28          [-1, 512, 28, 28]       1,180,160\n",
      "      BatchNorm2d-29          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-30          [-1, 512, 28, 28]               0\n",
      "           Conv2d-31          [-1, 512, 28, 28]       2,359,808\n",
      "      BatchNorm2d-32          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-33          [-1, 512, 28, 28]               0\n",
      "           Conv2d-34          [-1, 512, 28, 28]       2,359,808\n",
      "      BatchNorm2d-35          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-36          [-1, 512, 28, 28]               0\n",
      "           Conv2d-37          [-1, 512, 28, 28]       2,359,808\n",
      "      BatchNorm2d-38          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-39          [-1, 512, 28, 28]               0\n",
      "        MaxPool2d-40          [-1, 512, 14, 14]               0\n",
      "           Conv2d-41          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-42          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-43          [-1, 512, 14, 14]               0\n",
      "           Conv2d-44          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-45          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-46          [-1, 512, 14, 14]               0\n",
      "           Conv2d-47          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-48          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-49          [-1, 512, 14, 14]               0\n",
      "           Conv2d-50          [-1, 512, 14, 14]       2,359,808\n",
      "      BatchNorm2d-51          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-52          [-1, 512, 14, 14]               0\n",
      "        MaxPool2d-53            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-54            [-1, 512, 1, 1]               0\n",
      "           Linear-55                 [-1, 1024]         525,312\n",
      "             ReLU-56                 [-1, 1024]               0\n",
      "          Dropout-57                 [-1, 1024]               0\n",
      "           Linear-58                 [-1, 1024]       1,049,600\n",
      "             ReLU-59                 [-1, 1024]               0\n",
      "          Dropout-60                 [-1, 1024]               0\n",
      "           Linear-61                   [-1, 38]          38,950\n",
      "================================================================\n",
      "Total params: 21,649,254\n",
      "Trainable params: 21,610,406\n",
      "Non-trainable params: 38,848\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 351.66\n",
      "Params size (MB): 82.59\n",
      "Estimated Total Size (MB): 434.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "VGG_types = {\n",
    "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"VGG16\": [\n",
    "        64,\n",
    "        64,\n",
    "        \"M\",\n",
    "        128,\n",
    "        128,\n",
    "        \"M\",\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "    ],\n",
    "    \"VGG19\": [\n",
    "        64,\n",
    "        64,\n",
    "        \"M\",\n",
    "        128,\n",
    "        128,\n",
    "        \"M\",\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "class VGGnet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=38):\n",
    "        super(VGGnet, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG19\"])\n",
    "        self.global_avg_pooling = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "\n",
    "        # Modify the fully connected layers to match the new input size\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(512, 1024),  # Adjust input size from 512*7*7 to 512\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, 1024),  # Example: Adding an extra layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(1024, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = self.global_avg_pooling(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "\n",
    "    def create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for x in architecture:\n",
    "            if type(x) == int:\n",
    "                out_channels = x\n",
    "\n",
    "                layers += [\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=(3, 3),\n",
    "                        stride=(1, 1),\n",
    "                        padding=(1, 1),\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(x),\n",
    "                    nn.ReLU(),\n",
    "                ]\n",
    "                in_channels = x\n",
    "            elif x == \"M\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = VGGnet(in_channels=3, num_classes=38).to(device)\n",
    "\n",
    "\n",
    "freeze_layers = 5\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    if i < freeze_layers:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Verify which layers are frozen\n",
    "for name, param in model.named_parameters():\n",
    "    if not param.requires_grad:\n",
    "        print(f'Layer {name} is frozen.')\n",
    "\n",
    "# Print model summary\n",
    "summary(model.to(device), (3, 224, 224))  # Adjust input size as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad90426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "# Define the path to the single test image you want to test\n",
    "single_test_image_path = 'test/test/'\n",
    "\n",
    "# Define the transformation for the single test image\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Create the main window\n",
    "root = tk.Tk()\n",
    "root.title(\"Plant leaf disease detection\")\n",
    "tk.Label(root,text=\"PLANT LEAF DISEASE DETECTION USING VGG19\",width=10,height=4,bg=\"lightblue\",font='arial 20 bold').pack(side=tk.TOP,fill=tk.X)\n",
    "display_width = 600\n",
    "display_height = 600\n",
    "\n",
    "default_image_path = 'Sample-Images-from-Plant-village-dataset.png'\n",
    "default_image = Image.open(default_image_path)\n",
    "default_image = default_image.resize((display_width, display_height))  # Resize the image to fit the window\n",
    "\n",
    "# Convert the image to PhotoImage\n",
    "image_on_label = ImageTk.PhotoImage(default_image)\n",
    "# Create a label to display the image\n",
    "image_label = tk.Label(root, image=image_on_label)\n",
    "image_label.pack(side=tk.LEFT,padx=10,pady=10)\n",
    "\n",
    "\n",
    "# Load the trained model\n",
    "model = VGGnet(in_channels=3, num_classes=38)\n",
    "model.load_state_dict(torch.load('best_model_epoch_5.pt', map_location=device))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "def upload_image():\n",
    "    global single_test_image_path\n",
    "    single_test_image_path = filedialog.askopenfilename(filetypes=[(\"Image files\", \"*.jpg *.jpeg *.png\")])\n",
    "    update_display()\n",
    "\n",
    "def update_display():\n",
    "    # Load the single test image and apply the transformation\n",
    "    single_test_image = Image.open(single_test_image_path).convert('RGB')\n",
    "    input_image = test_transform(single_test_image).unsqueeze(0)  # Add a batch dimension\n",
    "\n",
    "    # Perform prediction\n",
    "    with torch.no_grad():\n",
    "        output = model(input_image)\n",
    "\n",
    "    # Get predicted class and confidence\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "    confidence = F.softmax(output, dim=1)[0][predicted_class].item()\n",
    "    predicted_class_name = class_names[predicted_class]\n",
    "\n",
    "    # Convert the input image to NumPy array\n",
    "    input_image_np = input_image.squeeze(0).permute(1, 2, 0).numpy()\n",
    "    input_image_np = (input_image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])).clip(0, 1)  # Reverse normalization\n",
    "\n",
    "    # Update the display\n",
    "    predicted_image = ImageTk.PhotoImage(Image.fromarray((input_image_np * 255).astype('uint8')))\n",
    "    predicted_label.config(image=predicted_image)\n",
    "    predicted_label.image = predicted_image\n",
    "\n",
    "    result_label.config(text=f'Predicted: {predicted_class_name} ({confidence:.2f})')\n",
    "\n",
    "text_above_button = tk.Label(root, text=\"Upload a image to predict the disease\", font=(\"Helvetica\", 16))\n",
    "text_above_button.pack(pady=10)\n",
    "\n",
    "# Create and place widgets\n",
    "upload_button = tk.Button(root, text=\"Upload Image\", command=upload_image)\n",
    "upload_button.pack(pady=10)\n",
    "\n",
    "predicted_label = tk.Label(root)\n",
    "predicted_label.pack()\n",
    "\n",
    "result_label = tk.Label(root, text=\"\", font=(\"Helvetica\", 16))\n",
    "result_label.pack(pady=10)\n",
    "\n",
    "# Start the Tkinter main loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad01c4b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c86802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb1c80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
